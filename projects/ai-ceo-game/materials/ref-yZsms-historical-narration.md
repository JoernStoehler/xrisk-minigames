# Historical Narration: The Real World Before the Game

A factual account of AI industry events from October 2024 through February 2026. Scenario writers use this as ground truth for backstory. The game begins October 14, 2026 — everything below has already happened when the player sits down.

This document covers: model releases, corporate dynamics, safety developments, regulation, infrastructure, and public discourse. Events are organized chronologically with narrative connective tissue explaining why each matters.

---

## Q4 2024: The Reasoning Era Begins

### October 2024

OpenAI closes a **$6.6 billion funding round at $157 billion valuation** (Oct 2), the largest venture round in history at the time. Led by Thrive Capital, with Microsoft (~$750M), SoftBank ($500M), and Nvidia ($100M). A clawback clause requires OpenAI to convert to for-profit within two years or return the money.

The round comes after a turbulent six months. Since May 2024, OpenAI has lost co-founder **Ilya Sutskever** (who founds Safe Superintelligence Inc.), superalignment co-lead **Jan Leike** (who joins Anthropic, publicly stating "safety culture has taken a backseat to shiny products"), co-founder **John Schulman** (to Anthropic), CTO **Mira Murati**, Chief Research Officer **Bob McGrew**, and VP of Research **Barret Zoph** (all Sep 25). The **Superalignment team** — promised 20% of compute, routinely denied it — is dissolved in May. A **Mission Alignment team** is created the same day Murati leaves.

**Miles Brundage**, head of AGI Readiness, departs Oct 24: "Neither OpenAI nor any other frontier lab is ready, and the world is also not ready."

Meanwhile, **Anthropic releases an upgraded Claude 3.5 Sonnet** (Oct 22) with a breakthrough: **computer use** — the first frontier AI model that can navigate a desktop, move cursors, click buttons, and type. SWE-bench jumps from 33.4% to 49.0%. Anthropic also updates its Responsible Scaling Policy to v2.0.

**Google DeepMind wins both Nobel Prizes** — Physics (Geoffrey Hinton, Oct 8) and Chemistry (Demis Hassabis and John Jumper for AlphaFold, Oct 9). The symbolism is hard to miss: AI capabilities are now producing Nobel-worthy science.

The **Biden administration expands chip export controls**, adding 140 Chinese entities to the Entity List and extending restrictions to high-bandwidth memory and advanced packaging equipment.

California Governor **Newsom vetoes SB 1047** (Sep 29), the most ambitious US state AI safety bill, which would have required kill switches and safety testing for frontier models costing >$100M to train. He signs 17 lesser AI bills instead.

### November–December 2024

OpenAI's **"12 Days of OpenAI"** (Dec 5-20) showcases the full o1 reasoning model, **Sora** (text-to-video), and announces **o3** (skipping "o2" due to trademark conflicts with Telefonica's O2). o3 scores **75.7% on ARC-AGI** — up from GPT-4o's ~5% — signaling a step change in reasoning ability.

**Google announces Gemini 2.0** (Dec 11) with agentic prototypes: Project Astra (universal assistant), Project Mariner (browser agent), and Jules (code agent). **DeepSeek quietly releases V3** — 671B parameters, trained for a claimed $6 million, a fraction of comparable Western models.

Anthropic publishes its **updated Responsible Scaling Policy (v2.2)** — more flexible but criticized for shifting from hard red lines to leadership judgment.

OpenAI lays out **for-profit transition plans** (Dec 27): the nonprofit would sell its control, the for-profit becomes a Delaware Public Benefit Corporation, and Altman would receive equity (reportedly ~7%, worth ~$10B).

The **UN General Assembly establishes an Office for Digital and Emerging Technologies** (ODET) effective Jan 1, 2025. AI safety incidents surge **56.4% year-over-year** (149 → 233). US state legislatures introduce 635 AI-related bills; 99 are enacted.

---

## Q1 2025: DeepSeek Shock and the Trump Pivot

### January 2025

Three events in one week reshape the AI landscape:

**Jan 20: Trump inaugurated; revokes Biden's AI Executive Order** (EO 14110) within hours, calling it "unpopular, inflationary, illegal." Signs EO 14179, "Removing Barriers to American Leadership in AI," shifting US policy from safety to deregulation and competitiveness.

**Jan 20: DeepSeek releases R1**, a 671B-parameter reasoning model under the MIT License. It matches OpenAI's o1 on key benchmarks at dramatically lower cost. Trained using reinforcement learning, efficiently distilled down to models as small as 1.5B parameters.

**Jan 21: Trump announces the Stargate Project** at a White House press conference with Sam Altman, Larry Ellison (Oracle), and Masayoshi Son (SoftBank). $500 billion planned over four years for AI data center infrastructure. Initial $100B deployment begins in Abilene, Texas. Elon Musk publicly disputes the funding claims.

**Jan 26: DeepSeek becomes the #1 app** on Apple's US App Store, displacing ChatGPT. The next day, **"DeepSeek Monday"** — Nvidia loses ~$600 billion in market cap in a single day, the largest single-stock loss in US history. NASDAQ drops 3%+. Marc Andreessen calls it "AI's Sputnik moment." The message: frontier AI can be built cheaply, export controls aren't working, and the US lead may be narrower than assumed.

Biden's last-minute **"AI Diffusion Rule"** (Jan 13) establishes a three-tier country framework for AI chip exports. Nvidia calls it a "200+ page regulatory morass."

### February 2025

The **EU AI Act's prohibited practices take effect** (Feb 2): bans on social scoring, manipulative AI, and predictive policing by profiling.

The **France AI Action Summit** (Feb 10-11, successor to Bletchley Park and Seoul) is notably rebranded from "Safety" to "Action" — signaling a global pivot toward AI adoption. 58 countries sign a joint declaration; the **US and UK refuse to sign**. Macron announces ~€110B in private AI investment for France.

The **International AI Safety Report** is published (96 experts, commissioned after Bletchley Park): AI capabilities are improving across cyber, biology, and chemistry domains. The **AI Safety Clock moves to 24 minutes to midnight** (from 29 in Sep 2024).

**Andrej Karpathy coins "vibe coding"** — "you fully give in to the vibes, embrace exponentials, and forget that the code even exists." The term goes viral, later named Collins Dictionary Word of the Year 2025. Y Combinator reports 25% of its Winter 2025 batch has codebases 95% AI-generated.

**xAI releases Grok 3** (Feb 17), trained on Colossus (200K H100 GPUs). Anthropic launches **Claude Code** as a command-line coding tool.

**John Schulman leaves Anthropic** after only ~6 months, joining Mira Murati's new startup **Thinking Machines Lab**.

### March 2025

**Gemini 2.5 Pro Experimental** launches (Mar 25) — Google's most intelligent model, with built-in chain-of-thought reasoning. Scores 86.7% on AIME 2025 and 63.8% on SWE-bench Verified. Debuts #1 on LMArena.

**SSI raises at $30B valuation** (6x in 6 months). Anthropic raises ~$4.5B Series E at $61.5B. **METR publishes** a finding that AI agent task completion length doubles every ~7 months — consistent exponential growth.

OpenAI releases **GPT-4.5** (Feb 27, research preview) to mixed reviews ("wide but shallow") and **o3-mini** (Jan 31). Both are stepping stones, not breakthroughs.

---

## Q2 2025: The Race Accelerates

### April 2025

**Meta releases Llama 4** (Scout and Maverick) — their first natively multimodal, mixture-of-experts models. Scout offers a 10M token context window. Llama 4 Behemoth (288B active / ~2T total) is announced but not released.

**OpenAI releases o3 and o4-mini** (Apr 16) for general availability. Google announces the **Agent2Agent (A2A) protocol** for agent-to-agent communication. The infrastructure for autonomous AI agents is being standardized.

Trump requires **export licenses for Nvidia H20 sales to China**, effectively halting compliant chip sales (later reversed in July).

### May 2025

**OpenAI abandons the full for-profit conversion** (May 5). After pressure from civic leaders, former employees, and Nobel laureates, the nonprofit retains control; the for-profit arm becomes a PBC but under nonprofit governance. Altman hires **Fidji Simo** (former Instacart CEO) as CEO of Applications and says he'll refocus on "research, compute, and safety."

**Anthropic releases Claude Opus 4 and Sonnet 4** (May 22). Opus 4 is classified as "Level 3" on Anthropic's 4-point safety scale — the first model to trigger heightened ASL-3 deployment and security standards. Constitutional Classifiers are deployed to block CBRN misuse. Claude Code goes generally available.

### June 2025

**OpenAI hits $10 billion annualized revenue** — less than 3 years after ChatGPT's launch. Releases **o3-pro** (Jun 10). Gemini 2.5 Pro and Flash reach general availability.

---

## Q3 2025: Scale and Disquiet

### July 2025

**xAI releases Grok 4** (Jul 10), called "the most intelligent model in the world" by xAI. A $300/month SuperGrok Heavy tier is introduced.

**Ilya Sutskever becomes CEO of SSI** after co-founder Daniel Gross departs (Meta reportedly attempted to acquire SSI). Mira Murati's **Thinking Machines Lab raises $2B** at $10-12B valuation.

Trump signs executive orders at the All-In Podcast/Hill & Valley Forum, including **"Preventing Woke AI in the Federal Government."** The Trump administration reverses H20 chip export restrictions. **Stargate Norway** launches as the first European site.

### August 2025

**OpenAI releases GPT-5** (Aug 7) — a unified architecture combining reasoning (from o-series), multimodal processing, and agent capabilities. It becomes the default model in ChatGPT for all users.

**EU AI Act GPAI obligations take effect** (Aug 2): penalties up to €35M or 7% of global turnover for prohibited practices. China issues an **"AI Plus" initiative** targeting 70% AI agent penetration by 2027.

The compute buildout is staggering: US data center electricity consumption exceeds 4% of total US power, projected to triple by 2028. GPU power consumption has risen from 150W (CPU era) to 1,200W. Power transformer lead times reach 210 weeks.

### September 2025

**Anthropic releases Claude Sonnet 4.5** (Sep 29), scoring 77.2% on SWE-bench Verified (highest ever). Anthropic raises **$13B Series F at $183B valuation**, becoming the 4th most valuable private company globally.

**Mrinank Sharma** (head of Anthropic Safeguards Research) resigns, warning **"the world is in peril."** Another Anthropic researcher (Yao Shunyu) leaves for DeepMind over Anthropic labeling China an "adversarial nation."

**OpenAI announces 5 new Stargate data center sites** — nearly 7 GW planned capacity, over $400B investment. The **AI Safety Clock moves to 20 minutes to midnight**.

---

## Q4 2025: Records and Warnings

### October 2025

**OpenAI completes corporate restructuring** (Oct 28). The nonprofit becomes the OpenAI Foundation (26% ownership, ~$130B). Microsoft holds 27%. The for-profit is now OpenAI Group PBC. A **$6.6B secondary stock sale** values OpenAI at **$500 billion** — the world's most valuable private company.

The **Future of Life Institute publishes a "Statement on Superintelligence"** — 865 signatories including Hinton, Bengio, Wozniak, and Prince Harry — calling for a prohibition on superintelligence development until "broad scientific consensus" on safety. **64% of Americans agree** in polling.

Weekly ChatGPT users reach **800 million** (up from 500M in March).

### November 2025

**Nvidia and Microsoft announce up to $15B investment in Anthropic**, which commits to $30B in Azure compute. Anthropic releases **Claude Opus 4.5** (Nov 24), completing the 4.5 model family. xAI releases Grok 4.1.

**Zico Kolter** is named chair of OpenAI's Safety and Security Committee with authority to halt unsafe releases — a condition of the California/Delaware AG approvals of the restructuring.

**Google DeepMind releases Gemini 3 Pro preview** (late Nov). Google's viral "Nano Banana Pro" image generation attracts 10M+ new Gemini users.

### December 2025

**40+ researchers from OpenAI, DeepMind, Anthropic, and Meta publish a joint warning** that the window to monitor AI reasoning "could close forever."

**Trump signs EO "Ensuring a National Policy Framework for AI"** (Dec 11), directing the AG to challenge "unconstitutional" state AI laws. **Nvidia H200 exports to China** are permitted with a 25% surcharge — the most powerful AI chip ever approved for China export.

**xAI expands Colossus to ~2 GW capacity** with 555,000 GPUs. SoftBank completes its full **$40B investment** in OpenAI. Data center deals hit records: 100+ transactions, $182B in debt issuance.

**Mistral releases Mistral Large 3** (675B MoE) and nine Ministral 3 models under Apache 2.0. Anthropic donates **MCP to the Linux Foundation's Agentic AI Foundation** (co-founded with Block and OpenAI).

The **FLI AI Safety Index** finds no leading AI company has a credible plan to prevent catastrophic risks. AI is described as **"less regulated than sandwiches."**

---

## Early 2026: The State of Play

### January–February 2026

**OpenAI disbands the Mission Alignment team** (Feb 11) — 16 months after its creation. Team leader Joshua Achiam is moved to a "Chief Futurist" role. This is the **second time** OpenAI has dissolved a dedicated safety team (after Superalignment in May 2024). Safety is now "distributed" across product teams.

**xAI's Colossus 2 goes operational** (Jan 17) — the first gigawatt-scale AI training cluster, exceeding 1 million H100 equivalents. xAI completes a $20B Series E.

**Anthropic releases Claude Opus 4.6** (Feb 5). Anthropic's funding round, originally targeting $10B, exceeds **$30B at $380B valuation** — the second-largest venture deal of all time. Annualized revenue exceeds $14B (10x annual growth for three years running).

**ARC Prize 2025 results**: top commercial model on ARC-AGI-2 is Opus 4.5 (Thinking) at 37.6%. Humans average 60%. The grand prize remains unclaimed — AI still can't match human fluid intelligence on novel problems.

---

## Key Patterns for Scenario Writers

These patterns from real events should inform scenario backstory:

### 1. Safety teams keep dissolving
OpenAI has now disbanded two dedicated safety teams in under two years (Superalignment May 2024, Mission Alignment Feb 2026). Key safety researchers (Sutskever, Leike, Schulman, Brundage, Adler, Sharma) have departed across labs. The pattern: safety teams are created with fanfare, starved of resources, then quietly dissolved.

### 2. The money is overwhelming
OpenAI went from $157B to $500B valuation in one year. Anthropic from $41B to $380B. Total AI infrastructure investment exceeds $500B in commitments. This capital creates unstoppable momentum — no safety concern can overcome the economic incentive to deploy.

### 3. Competitive dynamics are global and accelerating
DeepSeek proved frontier AI can be built cheaply outside the US. Export controls aren't working. Chinese labs are months behind, not years. The competitive pressure comes from everywhere: Google, Anthropic, Meta (open source), xAI, DeepSeek, Mistral, SSI, Thinking Machines Lab.

### 4. Regulation lags hopelessly
The EU AI Act took years and its key provisions are still phasing in. The US has no federal AI law. Trump's approach is deregulation. The fastest regulatory action (UK AISI, state bills) is being preempted or defunded. AI capabilities advance on a timescale of months; legislation takes years.

### 5. Agent capabilities are the new frontier
Computer use (Oct 2024), Claude Code (Feb 2025), MCP/A2A protocols, coding agents achieving 77%+ on SWE-bench — AI systems are becoming autonomous actors, not just answer machines. The infrastructure for AI agents to operate independently is being built in the open.

### 6. Public concern exists but doesn't translate to action
64% of Americans support prohibiting superintelligence development. The AI Safety Clock is at 20 minutes to midnight. Nobel laureates are signing letters. None of this has produced binding regulation. The gap between public concern and policy action is the defining political failure of the period.

### 7. Capability gains are relentless
From GPT-4o to GPT-5 in 15 months. From o1-preview to o4-mini in 7 months. SWE-bench from 33% to 77% in one year. Agent task completion length doubling every 7 months. Each new model makes the previous state of the art look quaint.

---

## Items Marked Uncertain

- **Stargate construction status (Aug 2025)**: Bloomberg reported the project "had not started" but earlier reports described construction in Abilene, TX. May refer to different phases.
- **SpaceX acquiring xAI (Jan 2026)**: Mentioned in one source, not widely corroborated.
- **DeepSeek's $6M training cost**: Widely described as a marginal cost excluding infrastructure, prior research, and team costs.
- **Jan Leike's departure from Anthropic**: Some sources may conflate this with Mrinank Sharma's departure. Exact date and attribution unclear.
- **Claude 4 Sonnet exact release date (~March 2025)**: Sources vary on timing.
- **GPT-5.1/5.2**: Referenced in some sources but not confirmed as distinct public releases.
