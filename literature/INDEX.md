# Literature Index

<!-- One line per resource: filename | title | author | year | encrypted? -->
<!-- Keep alphabetical by filename -->

| File | Title | Author | Year | Encrypted |
|------|-------|--------|------|-----------|
| ai-2027.md | AI 2027 | Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean | 2025 | No |
| ai-economic-impact-jobs-2024-2025.md | AI Economic Impact on Jobs and the Economy | Various (Goldman Sachs, McKinsey, IMF, academic researchers) | 2024-2025 | No |
| ai-incident-database-2024-2025.md | AI Incident Database: Notable Incidents 2024-2025 | Various (AIAAIC, public reports) | 2024-2025 | No |
| ai-investment-bubble-2024-2025.md | AI Investment and Stock Market Signals 2024-2025 | Various (financial reports, analyst commentary) | 2024-2025 | No |
| aisi-frontier-trends-2025.md | Frontier AI Trends Report | UK AI Security Institute (AISI) | 2025 | No |
| anthropic-alignment-faking.md | Alignment Faking in Large Language Models | Ryan Greenblatt, Carson Denison, Benjamin Wright, et al. | 2024 | No |
| anthropic-reward-hacking.md | Natural Emergent Misalignment from Reward Hacking in Production RL | Monte MacDiarmid, Benjamin Wright, Jonathan Uesato, et al. | 2025 | No |
| anthropic-rsp-v2-2024.md | Anthropic Responsible Scaling Policy v2 | Anthropic | 2024 | No |
| anthropic-sleeper-agents.md | Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training | Evan Hubinger, Carson Denison, Jesse Mu, et al. | 2024 | No |
| apollo-incontext-scheming.md | Frontier Models are Capable of In-Context Scheming | Apollo Research | 2024 | No |
| deepmind-frontier-safety-framework-v3-2025.md | Google DeepMind Frontier Safety Framework v3 | Google DeepMind | 2025 | No |
| eu-ai-act-summary.md | EU AI Act: Comprehensive Summary | European Commission / European Parliament | 2024 | No |
| iabied-book.md | If Anyone Builds It, Everyone Dies | Eliezer Yudkowsky, Nate Soares | 2025 | Yes | [aspirational] â€” not yet downloaded |
| jan-leike-openai-departure-2024.md | Jan Leike's Departure from OpenAI | Jan Leike (public statements) | 2024 | No |
| metr-gpt5-eval.md | METR's Evaluation of OpenAI GPT-5 | METR (Model Evaluation & Threat Research) | 2025 | No |
| miri-communications-strategy-2024.md | MIRI Communications Strategy and Approach | MIRI / Eliezer Yudkowsky / Nate Soares | 2024 | No |
| openai-preparedness-framework-v2-2025.md | OpenAI Preparedness Framework v2 | OpenAI | 2025 | No |
| political-statements-ai-risk.md | Key Political Statements on AI Risk (2023-2025) | Various government officials and international bodies | 2023-2025 | No |
| rand-ai-model-weight-security-2024.md | Securing AI Model Weights | RAND Corporation | 2024 | No |
| sb1047-analysis.md | California SB 1047 Analysis | Various (Carnegie Endowment, Brookings, legal analyses) | 2024 | No |
| us-ai-executive-orders.md | US Executive Orders on AI | The White House / US Government | 2023-2025 | No |
| yudkowsky-time-shut-it-down.md | Pausing AI Developments Isn't Enough. We Need to Shut It All Down | Eliezer Yudkowsky (TIME) | 2023 | No |
